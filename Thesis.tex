\documentclass[master]{outhesis}

\title{Master's Thesis}
\author{Bryan Hoke}
\degreename{Master of Science in Computer Science}
\school{University of Oklahoma}
\chair{Dr. Dean Hougen}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}

\graphicspath{ {Figures/} }

\newcommand{\mutationrate}{0.1}
\newcommand{\crossoverrate}{0.8}
\newcommand{\populationsize}{40}
\newcommand{\learningrulesize}{35}

\begin{document}
\makefrontmatter

% Introduction
\chapter{Introduction}

Chalmers [citation needed] demonstrated that evolutionary processes can produce systems that learn.
However, in Chalmers's work learning was the only phenotypic strategy that could emerge from evolution.
If other strategies, such as hard-coded behavior, were able to emerge alongside the strategy of learning, it might be found that learning is not always the strategy that emerges from evolution.
Presumably, the evolutionary environment (or objective function) would have the effect of influencing which strategies are more likely to emerge; after all, it is reasonable to think that no one strategy would always be optimal for every possible kind of environment.
This work examines how the introduction of "nurturing" into the environment influences the evolution of learning as opposed to an "instinctual" strategy where behavior is hard-coded.

% Hypothesis
\chapter{Hypothesis}

Three factors are considered with respect to their effects on the evolution of learning: the number of tasks, nurturing, and instincts.

Chalmers demonstrated that the likelihood of evolving generalized learning mechanisms is proportional to the number of tasks .

Nurturing alone will have little impact on the evolution of learning because learning is still the only strategy with or without nurturing. The likelihood of evolving generalized learning mechanisms will remain proportional to the number of tasks.

Instincts will be more likely to evolve than learning for small amounts of tasks, but learning will become more likely to evolve than instincts as the number of tasks increases. This will be because there will be a smaller number of instinct genes than learning genes to "tune" to a correct solution for small number of tasks, but because the number of genes required to represent instincts will increase as the number of tasks increases the number of instinct genes will become much larger than the number of learning genes as the number of tasks increases.

The introduction of the ability to evolve initial network weights alongside learning rules allows for the evolution of "instincts" as an alternate strategy to learning. Learning will be more likely to evolve in the nurturing condition than in the non-nurturing condition because of the costs associated with the learning process in the non-nurturing condition. 

% Operational Definitions
\chapter{Operational Definitions}

Instincts are to be represented by the genetically encoded initial weights of a network.

Learning is to be represented by the genetically encoded learning rule that is applied to a network throughout its lifetime.

For evolved networks where both initial weights and learning rules are genetically encoded, instincts are measured by removing the learning rule and evaluating the fitness of the network in the environment in which it was evolved.
For the same networks, learning ability is measured by replacing the genetically encoded initial weights with random initial weights and evaluating the fitness of the network in the environment in which it was evolved; generalized learning ability is measured by evaluating the fitness of this instinct-removed network in an environment different from the one in which it was evolved.

By default, mistakes made by a network during learning will count against its lifetime fitness; this is the "non-nurturing" condition.
In the "nurturing" condition, then, mistakes made by a network during learning will not count against its lifetime fitness.

% Procedure
\chapter{Procedure}

%% Implementation Details
\section{Implementation Details}

%%% Genetic Coding of Learning Mechanisms
\subsection{Genetic Coding of Learning Mechanisms}

\begin{center}
	$a_j$ the activation of the input unit $j$
\end{center}

\begin{center}
	$o_i$ the activation of the output unit $i$
\end{center}

\begin{center}
	$t_i$ the training signal on output unit $i$
\end{center}

\begin{center}
	$w_{ij}$ the current value of the connection strength from input $j$ to output $i$
\end{center}

The genome encodes a function $F$ such that

\[
	\Delta w_{ij} = F(a_j, o_i, t_i, w_{ij})
\]

$F$ is a linear function of its four parameters and their six pairwise products. Thus $F$ is determined by specifying ten coefficients.

The genome encodes these ten coefficients, as well as an eleventh "scale" parameter.

\[
	\Delta w_{ij} = k_0(k_1w_{ij}+k_2a_j+k_3o_i+k_4t_i+k_5w_{ij}a_j+k_6w_{ij}o_i+k_7w_{ij}t_{i}+k_8a_jo_i+k_9a_jt_i+k_{10}o_it_i)
\]

The portion of the genome which encodes $\Delta w_{ij}$ consists of 35 bits. The first five bits encode the scale parameter $k_0$ such that it can represent the values $0$, $\pm 1/256$, $\pm 1/128$, ..., $\pm 32$, $\pm 64$, via exponential encoding. The first bit encodes the sign of $k_0$ (0: negative, 1: positive), and the next four bits encode the magnitude. If these four bits are interpreted as an integer $j$ between 0 and 15, we have

\[
	|k_0|=
	\begin{cases}
		0 & \text{if $j = 0$}\\
		2^{j-9} & \text{if $j = 1, ..., 15$}
	\end{cases}
\]

The other 30 bits encode the other ten coefficients in groups of three. The first bit of each group expresses the sign, and the other two bits express a magnitude of 0, 1, 2, or 4 via a similar exponential encoding. If we interpret these two bits as an integer $j$ between 0 and 3, then

\[
	|k_i|=
	\begin{cases}
		0 & \text{if $j = 0$}\\
		2^{j-1} & \text{if $j = 1, 2, 3$}
	\end{cases}
\]

%%% Genetic Coding of Initial Weights
\subsection{Genetic Coding of Initial Weights}

Network weights are evolved alongside learning rules. It would not be meaningful for each chromosome to represent a single set of weights to be used on all tasks, so instead each chromosome simultaneously represents a distinct set of weights for every task in the evolutionary run. The weights to be applied to each evolutionary task are encoded in distinct, consistent regions of each chromosome. 

\newcommand{\bitsperweight}{3}
\newcommand{\jlen}{2}
\newcommand{\jmin}{0}
\newcommand{\jmax}{3}
\newcommand{\exponentshift}{4}

Weights are encoded using 3 bits each. The first bit is the sign of the weight. If we interpret these two bits as an integer $j$ between 0 and 3, then

\[
	|k_i|=
	\begin{cases}
		0 & \text{if $j = 0$}\\
		2^{j-4} & \text{if $j = 1, 2, 3$}
	\end{cases}
\]

For each task the number of weights encoded is equal to the number of inputs in that task plus one bias weight.

There are two conditions of evaluation: the "nurturing" case and the "non-nurturing" case. During evaluation, each network is first trained for 10 epochs using its learning rule. Following this, the network is evaluated on the same tasks. In the "nurturing" case the individual's fitness is simply the result of the evaluation, whereas in the "non-nurturing" case the individual's fitness is the average of evaluation during all training epochs and the final evaluation.

%%% Evaluation of Fitness
\subsection{Evaluation of Fitness}

Fitness evaluation for the nurturing case:

(1) Create a network with the appropriate number of input units for the task and a single output unit.

(2) Initialize the connection strengths of the network using the values encoded in the chromosome

(3) For 10 epochs, cycle through the training exemplars for the task, where for each exemplar we:

(3a) Propagate input values through the system, yielding output values; then

(3b) Adjust the weights of the system according to the formula specified by the learning procedure, on the basis of inputs, output, training signal, and current weights.

(4) At the end of this process, fitness on the task is measured by testing the network on all training exemplars, and dividing the total error by the number of exemplars, subtracting from 1, and multiplying by 100. This yields a fitness "percentage" between 0 and 100.

Fitness evaluation for the non-nurturing case:

(1) Create a network with the appropriate number of input units for the task and a single output unit.

(2) Initialize the connection strengths of the network using the values encoded in the chromosome

(3) For 10 epochs, cycle through the training exemplars for the task, where for each exemplar we:

(3a) Test the network on the exemplar and measure the error in the network output; then

(3b) Propagate input values through the system, yielding output values, then adjust the weights of the system according to the formula specified by the learning procedure, on the basis of inputs, output, training signal, and current weights.

(4) At the end of this process, test the network on all training exemplars and divide the total error of this test and all tests from step 3a by the total number of tests that occurred, subtracting from 1, and multiplying by 100. This yields a fitness "percentage" between 0 and 100.

Fitness of the chromosome is obtained by evaluating its performance on each of the (typically 20) tasks, and taking the mean fitness over all tasks. In this way every chromosome is assigned a fitness between 0 and 100\%.

%%% Parameters of the Genetic Algorithm
\subsection{Parameters of the Genetic Algorithm}

% TODO: Describe GA used
% TODO: Describe "segment-wise" crossover used

Population size: 40
Crossover rate: 0.8
Mutation rate: 0.01
Elitism factor: 1
Number of generations: 4000

%%% Post-Evolutionary Evaluation
\subsection{Post-Evolutionary Evaluation}

Before each evolutionary run, 10 tasks are selected from the task pool and designated as "test tasks". After each evolutionary run, the chromosome with the highest fitness score in the history of the populations in that run is identified. From this chromosome, the learning rule bits are isolated and evaluated on the test tasks (using both the nurturing and non-nurturing conditions) and the weight-encoding bits are isolated and evaluated on the evolutionary tasks.

% Results
\chapter{Results}

%% Results of initial evolutionary runs
\section{Results of initial evolutionary runs}

\begin{figure}[H]
	\centering
	\includegraphics{ChalmersEvolution.pdf}
	\caption{The evolution of maximum fitness for populations evaluated using 20 tasks under the nurturing and non-nurturing conditions.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics{ChalmersLearningTest.pdf}
	\caption{The average generalized learning capabilities for the best individuals evolved under the nurturing and non-nurturing conditions.}
\end{figure}

%% Fitness test
\section{Fitness test}

The best individual is re-evaluated on the evolutionary tasks using both the nurturing and non-nurturing conditions (recall that it is evaluated using only one of these conditions during evolution).

In both cases it is clear that the objective function becomes more difficult to satisfy as the number of evolutionary tasks increases. 

Individuals evolved using the non-nurturing case perform better when re-evaluated using the non-nurturing case than when using the nurturing case, and individuals evolved using the nurturing case perform better when re-evaluated using the nurturing case than when using the non-nurturing case.

\begin{figure}[H]
	\centering
	\includegraphics{NonNurturingFitnessTestPlot.pdf}
	\caption{Non-nurturing fitness test on evolutionary tasks for individuals evolved under the nurturing and non-nurturing conditions.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics{NurturingFitnessTestPlot.pdf}
	\caption{Nurturing fitness test on evolutionary tasks for individuals evolved under the nurturing and non-nurturing conditions.}
\end{figure}

%% Network test
\section{Network test}

The portion of the chromosome which encodes the network weights is isolated and evaluated on the evolutionary tasks by initializing a network with the encoded weights, with the intention of determining the contribution of the portion of the chromosome which encodes the initial weights to the fitness of the whole chromosome.

Networks evolved using the non-nurturing condition performed better on this evaluation than networks evolved using the nurturing condition, suggesting that the initial weights make a larger contribution to fitness in the non-nurturing case than in the nurturing case.
% TODO: Suggest that learning plays a somewhat less important role in the non-nurturing case?

\begin{figure}[H]
	\centering
	\includegraphics{NetworkTestPlot.pdf}
	\caption{Network test on evolutionary tasks for individuals evolved under the nurturing and non-nurturing conditions.}
\end{figure}

%% Learning Improvement
\section{Learning Improvement}

To determine the average amount of useful learning that evolves for a given number of tasks we can examine the difference between the evolutionary fitness and the network fitness.
This is because the network fitness is essentially the same as an individual's fitness before it undergoes learning processes, whereas the evolutionary fitness is an individual's fitness after it undergoes learning processes.

As shown in Figure 4.4, the improvement in fitness due to learning increases as the number of evolutionary tasks increases. This suggests that learning becomes an increasingly important evolutionary strategy as the environment becomes more varied.

\begin{figure}[H]
	\centering
	\includegraphics{LearningImprovementPlot.pdf}
	\caption{The difference between evolutionary fitness and network fitness for individuals evolved under the nurturing and non-nurturing conditions.}
\end{figure}

%% Learning test
\section{Learning test}

The portion of the chromosome which encodes the learning rule is isolated and evaluated on the evolutionary tasks by initializing a network with random weights and the encoded learning rule, with the intention of determining the contribution of the portion of the chromosome which encodes the learning rule to the fitness of the whole chromosome.

In both cases of evaluation the learning rule evolved using the nurturing condition performed better than the learning rule evolved using the non-nurturing condition, suggesting that the learning rule makes a larger contribution to fitness in the nurturing case than in the non-nurturing case.
% TODO: Suggest that learning plays a somewhat more important role in the nurturing case?

\begin{figure}[H]
	\centering
	\includegraphics{NonNurturingLearningTestPlot.pdf}
	\caption{Non-nurturing learning test on evolutionary tasks for individuals evolved under the nurturing and non-nurturing conditions.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics{NurturingLearningTestPlot.pdf}
	\caption{Nurturing learning test on evolutionary tasks for individuals evolved under the nurturing and non-nurturing conditions.}
\end{figure}

%% Generalization test
\section{Generalization test}

The portion of the chromosome which encodes the learning rule is isolated and evaluated on the test tasks by initializing a network with random weights and the encoded learning rule, with the intention of determining the capacity for generalized learning that was evolved.

In both cases of evaluation the learning rule evolved using the nurturing condition outperformed the learning rule evolved using the non-nurturing condition, suggesting that better generalized learning is more likely to evolve using the nurturing case.

\begin{figure}[H]
	\centering
	\includegraphics{NonNurturingGeneralizationTestPlot.pdf}
	\caption{Non-nurturing generalization test on test tasks for individuals evolved under the nurturing and non-nurturing conditions.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics{NurturingGeneralizationTestPlot.pdf}
	\caption{Nurturing generalization test on test tasks for individuals evolved under the nurturing and non-nurturing conditions.}
\end{figure}

% Conclusion
\chapter{Conclusion}

The impact of varying the nurturing condition alone was insignificant; fitnesses measured under the nurturing condition were generally higher than those measured under the non-nurturing condition, but this is to be expected because of the additional fitness penalties imposed by the non-nurturing condition.

When instincts and learning were allowed to evolve alongside each other, it was found that instinct-based solutions were more likely to evolve for small numbers of evolutionary tasks, but that learning became more likely to evolve as the number of evolutionary tasks increased.

By varying the nurturing condition when instincts were allowed to evolve alongside learning, it was found that instinct-based solutions were more likely to evolve under the non-nurturing condition whereas learning was more likely to evolve under the nurturing condition.

\makebackmatter
\end{document}